# -*- coding: utf-8 -*-
"""
æ‘„å½±è¯„ç‰‡æ¨¡å—
ä½¿ç”¨ VLM æ¨¡å‹è¿›è¡Œä¸“ä¸šæ‘„å½±è¯„ä»·
"""

import os
import time
import json
from pathlib import Path
from typing import Optional, Dict, Any, List
from PIL import Image
from dataclasses import dataclass
from enum import Enum


class DetailLevel(Enum):
    """è¯„ç‰‡è¯¦ç»†ç¨‹åº¦"""
    BRIEF = "brief"       # ç®€çº¦ 100-200 å­—
    NORMAL = "normal"     # æ­£å¸¸ 300-400 å­—
    DETAILED = "detailed" # è¯¦ç»† â‰¤500 å­—


@dataclass
class CritiqueConfig:
    """è¯„ç‰‡é…ç½®"""
    detail_level: DetailLevel = DetailLevel.NORMAL
    enable_title: bool = False
    enable_keywords: bool = False
    enable_scene: bool = False
    enable_critique: bool = True
    enable_exif_analysis: bool = True  # é»˜è®¤å¼€å¯


# æ¨¡å‹å•ä¾‹
_model = None
_processor = None
_config = None


def get_model():
    """è·å–æˆ–åŠ è½½æ¨¡å‹ï¼ˆå•ä¾‹ï¼‰"""
    global _model, _processor, _config
    
    if _model is not None:
        return _model, _processor, _config
    
    print("[æ‘„å½±è¯„ç‰‡] æ­£åœ¨åŠ è½½æ¨¡å‹...")
    start = time.time()
    
    from mlx_vlm import load
    from mlx_vlm.utils import load_config
    
    MODEL_PATH = "lmstudio-community/Qwen3-VL-8B-Instruct-MLX-8bit"
    
    _model, _processor = load(MODEL_PATH)
    _config = load_config(MODEL_PATH)
    
    print(f"[æ‘„å½±è¯„ç‰‡] æ¨¡å‹åŠ è½½å®Œæˆ ({time.time() - start:.1f}s)")
    return _model, _processor, _config


def unload_model():
    """å¸è½½æ¨¡å‹é‡Šæ”¾å†…å­˜"""
    global _model, _processor, _config
    if _model is not None:
        del _model, _processor, _config
        _model = _processor = _config = None
        import gc
        gc.collect()
        print("[æ‘„å½±è¯„ç‰‡] æ¨¡å‹å·²å¸è½½")


def prepare_image(image_path: str, max_size: int = 1024) -> str:
    """
    å‡†å¤‡å›¾ç‰‡ç”¨äºåˆ†æï¼Œè¿”å›ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    æ”¯æŒ RAW å’Œå¸¸è§„å›¾ç‰‡æ ¼å¼
    ç»Ÿä¸€å¤„ç†ä¸ºé•¿è¾¹ 1024px
    """
    path = Path(image_path)
    
    if not path.exists():
        raise FileNotFoundError(f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    # RAW æ ¼å¼
    raw_extensions = {'.cr2', '.cr3', '.nef', '.arw', '.orf', '.raf', '.rw2', '.dng', '.pef', '.raw'}
    
    if path.suffix.lower() in raw_extensions:
        # æ£€æŸ¥åŒå JPG
        for ext in ['.jpg', '.jpeg', '.JPG', '.JPEG']:
            jpg_path = path.with_suffix(ext)
            if jpg_path.exists():
                image = Image.open(jpg_path).convert("RGB")
                break
        else:
            # ä½¿ç”¨ rawpy æå–ç¼©ç•¥å›¾
            import rawpy
            import io
            with rawpy.imread(str(path)) as raw:
                thumb = raw.extract_thumb()
                if thumb.format == rawpy.ThumbFormat.JPEG:
                    image = Image.open(io.BytesIO(thumb.data)).convert("RGB")
                else:
                    rgb = raw.postprocess()
                    image = Image.fromarray(rgb).convert("RGB")
    else:
        image = Image.open(image_path).convert("RGB")
    
    # è°ƒæ•´å¤§å°ï¼šé•¿è¾¹ 1024px
    w, h = image.size
    if max(w, h) > max_size:
        if w > h:
            new_w, new_h = max_size, int(h * max_size / w)
        else:
            new_h, new_w = max_size, int(w * max_size / h)
        image = image.resize((new_w, new_h), Image.LANCZOS)
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = f"/tmp/photo_critic_{os.getpid()}.jpg"
    image.save(temp_path, "JPEG", quality=95)
    
    return temp_path


def extract_exif(image_path: str) -> Dict[str, Any]:
    """
    æå– EXIF ä¿¡æ¯
    è¿”å›æ›å…‰å‚æ•°ã€å™¨æã€æ—¶é—´ã€GPS ç­‰
    """
    exif_data = {}
    
    try:
        from PIL.ExifTags import TAGS, GPSTAGS
        
        image = Image.open(image_path)
        exif = image._getexif()
        
        if exif:
            for tag_id, value in exif.items():
                tag = TAGS.get(tag_id, tag_id)
                
                if tag == "Make":
                    exif_data["camera_make"] = str(value)
                elif tag == "Model":
                    exif_data["camera_model"] = str(value)
                elif tag == "LensModel":
                    exif_data["lens"] = str(value)
                elif tag == "FocalLength":
                    exif_data["focal_length"] = f"{value}mm" if isinstance(value, (int, float)) else str(value)
                elif tag == "FNumber":
                    exif_data["aperture"] = f"f/{value}" if isinstance(value, (int, float)) else str(value)
                elif tag == "ExposureTime":
                    if isinstance(value, tuple):
                        exif_data["shutter_speed"] = f"{value[0]}/{value[1]}s"
                    else:
                        exif_data["shutter_speed"] = f"{value}s"
                elif tag == "ISOSpeedRatings":
                    exif_data["iso"] = f"ISO {value}"
                elif tag == "DateTimeOriginal":
                    exif_data["datetime"] = str(value)
                elif tag == "GPSInfo":
                    # ç®€å• GPS å¤„ç†
                    try:
                        gps = {}
                        for key in value.keys():
                            decode = GPSTAGS.get(key, key)
                            gps[decode] = value[key]
                        if "GPSLatitude" in gps and "GPSLongitude" in gps:
                            exif_data["gps"] = True
                    except:
                        pass
    except Exception as e:
        exif_data["_error"] = str(e)
    
    return exif_data


def format_exif_context(exif_data: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ– EXIF ä¿¡æ¯ä¸º prompt ä¸Šä¸‹æ–‡"""
    if not exif_data or "_error" in exif_data:
        return ""
    
    parts = []
    
    if "camera_make" in exif_data and "camera_model" in exif_data:
        parts.append(f"ç›¸æœº: {exif_data['camera_make']} {exif_data['camera_model']}")
    if "lens" in exif_data:
        parts.append(f"é•œå¤´: {exif_data['lens']}")
    if "focal_length" in exif_data:
        parts.append(f"ç„¦è·: {exif_data['focal_length']}")
    if "aperture" in exif_data:
        parts.append(f"å…‰åœˆ: {exif_data['aperture']}")
    if "shutter_speed" in exif_data:
        parts.append(f"å¿«é—¨: {exif_data['shutter_speed']}")
    if "iso" in exif_data:
        parts.append(f"{exif_data['iso']}")
    if "datetime" in exif_data:
        parts.append(f"æ‹æ‘„æ—¶é—´: {exif_data['datetime']}")
    if exif_data.get("gps"):
        parts.append("(å«GPSä¿¡æ¯)")
    
    if parts:
        return "æ‹æ‘„å‚æ•°: " + ", ".join(parts)
    return ""


def read_one_align_scores(image_path: str) -> Dict[str, Any]:
    """
    ä» IPTC è¯»å– One-Align è¯„åˆ†
    City = è´¨é‡åˆ†, Province-State = ç¾å­¦åˆ†, Rating = æ˜Ÿçº§
    
    Returns:
        {
            "quality": float or None,
            "aesthetic": float or None,
            "rating": int or None,
            "has_scores": bool
        }
    """
    scores = {
        "quality": None,
        "aesthetic": None,
        "rating": None,
        "has_scores": False
    }
    
    try:
        from exif_writer import get_exif_writer
        writer = get_exif_writer()
        
        # è¯»å– IPTC å­—æ®µ
        result = writer.read_metadata(image_path)
        
        if result:
            # City = è´¨é‡åˆ†
            if "City" in result:
                try:
                    scores["quality"] = float(result["City"])
                except:
                    pass
            
            # Province-State = ç¾å­¦åˆ†
            if "Province-State" in result:
                try:
                    scores["aesthetic"] = float(result["Province-State"])
                except:
                    pass
            
            # Rating = æ˜Ÿçº§
            if "Rating" in result:
                try:
                    scores["rating"] = int(result["Rating"])
                except:
                    pass
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´è¯„åˆ†
        scores["has_scores"] = all([
            scores["quality"] is not None,
            scores["aesthetic"] is not None,
            scores["rating"] is not None
        ])
        
    except Exception as e:
        scores["_error"] = str(e)
    
    return scores


def get_one_align_scores(image_path: str) -> Dict[str, Any]:
    """
    è·å– One-Align è¯„åˆ†
    å¦‚æœ IPTC ä¸­å·²æœ‰è¯„åˆ†åˆ™ç›´æ¥è¿”å›ï¼Œå¦åˆ™è°ƒç”¨ One-Align æ¨¡å‹è·å–
    
    Returns:
        {
            "quality": float,
            "aesthetic": float,
            "total": float,
            "rating": int,
            "source": "iptc" | "one_align"
        }
    """
    # å…ˆå°è¯•ä» IPTC è¯»å–
    existing = read_one_align_scores(image_path)
    
    if existing["has_scores"]:
        # è®¡ç®—ç»¼åˆåˆ† (40% è´¨é‡ + 60% ç¾å­¦)
        total = existing["quality"] * 0.4 + existing["aesthetic"] * 0.6
        return {
            "quality": existing["quality"],
            "aesthetic": existing["aesthetic"],
            "total": total,
            "rating": existing["rating"],
            "source": "iptc"
        }
    
    # éœ€è¦è°ƒç”¨ One-Align è·å–è¯„åˆ†
    print("[æ‘„å½±è¯„ç‰‡] æœªæ‰¾åˆ°è¯„åˆ†ï¼Œè°ƒç”¨ One-Align æ¨¡å‹...")
    
    try:
        from one_align_scorer import get_one_align_scorer
        
        scorer = get_one_align_scorer()
        result = scorer.score_image(image_path)
        
        return {
            "quality": result["quality"],
            "aesthetic": result["aesthetic"],
            "total": result["total"],
            "rating": result["rating"],
            "source": "one_align"
        }
    except Exception as e:
        print(f"[æ‘„å½±è¯„ç‰‡] One-Align è¯„åˆ†å¤±è´¥: {e}")
        return {
            "quality": None,
            "aesthetic": None,
            "total": None,
            "rating": None,
            "source": "error",
            "_error": str(e)
        }


def format_scores_context(scores: Dict[str, Any]) -> str:
    """
    æ ¼å¼åŒ–è¯„åˆ†ä¿¡æ¯ä¸º prompt ä¸Šä¸‹æ–‡
    è®©è¯„ç‰‡æ¨¡å‹äº†è§£å›¾ç‰‡çš„è´¨é‡å’Œç¾å­¦æ°´å¹³
    """
    if not scores or scores.get("source") == "error":
        return ""
    
    parts = []
    
    if scores.get("quality") is not None:
        quality = scores["quality"]
        if quality >= 80:
            level = "ä¼˜ç§€"
        elif quality >= 70:
            level = "è‰¯å¥½"
        elif quality >= 60:
            level = "ä¸­ç­‰"
        else:
            level = "ä¸€èˆ¬"
        parts.append(f"æŠ€æœ¯è´¨é‡åˆ† {quality:.1f}/100 ({level})")
    
    if scores.get("aesthetic") is not None:
        aesthetic = scores["aesthetic"]
        if aesthetic >= 80:
            level = "å‡ºè‰²"
        elif aesthetic >= 70:
            level = "ä¸é”™"
        elif aesthetic >= 60:
            level = "ä¸­ç­‰"
        else:
            level = "ä¸€èˆ¬"
        parts.append(f"ç¾å­¦è¯„åˆ† {aesthetic:.1f}/100 ({level})")
    
    if scores.get("rating") is not None:
        rating = scores["rating"]
        stars = "â­" * rating if rating > 0 else "æ— æ˜Ÿ"
        parts.append(f"ç»¼åˆè¯„çº§ {rating}æ˜Ÿ ({stars})")
    
    if parts:
        return "AI åˆè¯„: " + ", ".join(parts)
    return ""


# ==================== Prompts ====================

DETAIL_SETTINGS = {
    DetailLevel.BRIEF: ("ç®€è¦ç‚¹è¯„100-200å­—", 250),
    DetailLevel.NORMAL: ("æ­£å¸¸ç‚¹è¯„300-400å­—", 500),
    DetailLevel.DETAILED: ("è¯¦ç»†ç‚¹è¯„ä¸è¶…è¿‡500å­—", 650),
}

CRITIQUE_TEMPLATE = """è¯·ä»¥ä¸“ä¸šæ‘„å½±å¸ˆè§†è§’è¯„ä»·è¿™å¼ ç…§ç‰‡ï¼š
{exif_context}
{scores_context}

1. æŠ€æœ¯ç‚¹è¯„ï¼šæ›å…‰/å¯¹ç„¦/æ„å›¾
2. è‰ºæœ¯ç‚¹è¯„ï¼šæƒ…ç»ª/å…‰å½±/è‰²å½©
3. ä¸»è¦ä¼˜ç‚¹(1-2ç‚¹)
4. éœ€æ”¹è¿›å¤„(1-2ç‚¹)
5. åæœŸå»ºè®®

{detail_instruction}ï¼Œç”¨ä¸­æ–‡ä¸“ä¸šç®€æ´å›ç­”ã€‚"""

TITLE_PROMPT = "ä¸ºè¿™å¼ ç…§ç‰‡åˆ›ä½œä¸€ä¸ªå¯Œæœ‰è¯—æ„çš„ä¸­æ–‡æ ‡é¢˜ï¼Œ5-10ä¸ªå­—ã€‚åªè¾“å‡ºæ ‡é¢˜ã€‚"

KEYWORDS_PROMPT = """åˆ—å‡ºè¿™å¼ ç…§ç‰‡ä¸­èƒ½çœ‹åˆ°çš„å…³é”®å…ƒç´ ï¼Œä¸è¶…è¿‡10ä¸ªè¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚
è¦æ±‚ï¼šå…·ä½“å¯è§äº‹ç‰©ï¼Œé¿å…æŠ½è±¡åè¯ï¼ˆå¦‚"ç¾ä¸½"ã€"è‡ªç„¶"ç­‰ï¼‰ã€‚"""

SCENE_PROMPT = """åˆ¤æ–­è¿™å¼ ç…§ç‰‡çš„åœºæ™¯ç±»å‹ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š
é£å…‰ã€äººåƒã€è¡—æ‹ã€å»ºç­‘ã€é‡ç”ŸåŠ¨ç‰©ã€é™ç‰©ã€ç¾é£Ÿã€è¿åŠ¨ã€æ–°é—»çºªå®ã€å©šç¤¼ã€å•†ä¸šäº§å“ã€å…¶ä»–
åªè¾“å‡ºä¸€ä¸ªåˆ†ç±»åç§°ã€‚"""


def generate(model, processor, config, prompt: str, image_path: str, max_tokens: int) -> str:
    """è°ƒç”¨æ¨¡å‹ç”Ÿæˆ"""
    from mlx_vlm import generate as mlx_generate
    from mlx_vlm.prompt_utils import apply_chat_template
    
    formatted_prompt = apply_chat_template(processor, config, prompt, num_images=1)
    
    response = mlx_generate(
        model,
        processor,
        formatted_prompt,
        image=[image_path],
        max_tokens=max_tokens,
        verbose=False
    )
    
    return response.text if hasattr(response, 'text') else str(response)


def critique(
    image_path: str,
    config: CritiqueConfig = None
) -> Dict[str, Any]:
    """
    æ‘„å½±è¯„ç‰‡ä¸»å‡½æ•°
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        config: è¯„ç‰‡é…ç½®
    
    Returns:
        {
            "success": True,
            "critique": "...",      # æ‘„å½±è¯„ç‰‡
            "title": "...",         # ä¸­æ–‡æ ‡é¢˜ (å¯é€‰)
            "keywords": "...",      # å…³é”®è¯ (å¯é€‰)
            "scene": "...",         # åœºæ™¯åˆ†ç±» (å¯é€‰)
            "exif": {...},          # EXIF ä¿¡æ¯
            "processing_time": 12.5
        }
    """
    if config is None:
        config = CritiqueConfig()
    
    start_time = time.time()
    result = {"success": False}
    temp_path = None
    
    try:
        # è·å–æ¨¡å‹
        model, processor, model_config = get_model()
        
        # å‡†å¤‡å›¾ç‰‡
        temp_path = prepare_image(image_path)
        
        # æå– EXIF
        if config.enable_exif_analysis:
            exif_data = extract_exif(image_path)
            result["exif"] = exif_data
            exif_context = format_exif_context(exif_data)
        else:
            exif_context = ""
        
        # è·å– One-Align è¯„åˆ†ï¼ˆå¿…è¦æ—¶è§¦å‘è¯„åˆ†ï¼‰
        scores = get_one_align_scores(image_path)
        result["scores"] = scores
        scores_context = format_scores_context(scores)
        
        # æ‘„å½±è¯„ç‰‡
        if config.enable_critique:
            detail_instruction, max_tokens = DETAIL_SETTINGS[config.detail_level]
            prompt = CRITIQUE_TEMPLATE.format(
                exif_context=exif_context,
                scores_context=scores_context,
                detail_instruction=detail_instruction
            )
            result["critique"] = generate(model, processor, model_config, prompt, temp_path, max_tokens)
        
        # ä¸­æ–‡æ ‡é¢˜
        if config.enable_title:
            result["title"] = generate(model, processor, model_config, TITLE_PROMPT, temp_path, 50)
        
        # å…³é”®è¯
        if config.enable_keywords:
            result["keywords"] = generate(model, processor, model_config, KEYWORDS_PROMPT, temp_path, 100)
        
        # åœºæ™¯åˆ†ç±»
        if config.enable_scene:
            result["scene"] = generate(model, processor, model_config, SCENE_PROMPT, temp_path, 20)
        
        result["success"] = True
        result["processing_time"] = round(time.time() - start_time, 2)
        
    except Exception as e:
        result["error"] = str(e)
        result["processing_time"] = round(time.time() - start_time, 2)
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)
    
    return result


# ==================== æµ‹è¯• ====================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python photo_critic.py <å›¾ç‰‡è·¯å¾„>")
        sys.exit(1)
    
    test_image = sys.argv[1]
    print(f"ğŸ“· æµ‹è¯•å›¾ç‰‡: {test_image}")
    print("=" * 60)
    
    # å®Œæ•´æµ‹è¯•
    config = CritiqueConfig(
        detail_level=DetailLevel.NORMAL,
        enable_title=True,
        enable_keywords=True,
        enable_scene=True,
        enable_critique=True,
        enable_exif_analysis=True
    )
    
    result = critique(test_image, config)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š è¯„ç‰‡ç»“æœ:")
    print("=" * 60)
    
    # æ˜¾ç¤º One-Align è¯„åˆ†
    if result.get("scores"):
        scores = result["scores"]
        print(f"\nâ­ One-Align è¯„åˆ† (æ¥æº: {scores.get('source', 'unknown')}):")
        if scores.get("quality") is not None:
            print(f"   æŠ€æœ¯è´¨é‡: {scores['quality']:.1f}/100")
        if scores.get("aesthetic") is not None:
            print(f"   ç¾å­¦è¯„åˆ†: {scores['aesthetic']:.1f}/100")
        if scores.get("total") is not None:
            print(f"   ç»¼åˆåˆ†: {scores['total']:.1f}/100")
        if scores.get("rating") is not None:
            print(f"   æ˜Ÿçº§: {'â­' * scores['rating']} ({scores['rating']}æ˜Ÿ)")
    
    if result.get("exif"):
        print(f"\nğŸ“¸ EXIF ä¿¡æ¯:")
        for k, v in result["exif"].items():
            if not k.startswith("_"):
                print(f"   {k}: {v}")
    
    if result.get("title"):
        print(f"\nğŸ·ï¸ æ ‡é¢˜: {result['title']}")
    
    if result.get("keywords"):
        print(f"\nğŸ”‘ å…³é”®è¯: {result['keywords']}")
    
    if result.get("scene"):
        print(f"\nğŸ¬ åœºæ™¯: {result['scene']}")
    
    if result.get("critique"):
        print(f"\nğŸ“ æ‘„å½±è¯„ç‰‡:")
        print("-" * 40)
        print(result["critique"])
    
    print(f"\nâ±ï¸ å¤„ç†æ—¶é—´: {result.get('processing_time', 0)}s")
