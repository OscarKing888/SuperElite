# -*- coding: utf-8 -*-
"""
Co-Instruct å•åŠŸèƒ½æµ‹è¯• - ä¸­æ–‡æ ‡é¢˜ï¼ˆè¯¦ç»†è®¡æ—¶ç‰ˆï¼‰
"""

import torch
import time
from pathlib import Path
from PIL import Image

# æµ‹è¯•å›¾ç‰‡
TEST_IMAGE = "/Volumes/990PRO4TB/2025/2025-09-20/_Z8L1493.NEF"

print("ğŸ“· Co-Instruct æµ‹è¯• - ä¸­æ–‡æ ‡é¢˜ç”Ÿæˆï¼ˆè¯¦ç»†è®¡æ—¶ï¼‰")
print("=" * 60)
print(f"æµ‹è¯•å›¾ç‰‡: {TEST_IMAGE}")

# ==================== è®¡æ—¶å¼€å§‹ ====================
total_start = time.time()

# æ­¥éª¤ 1: åŠ è½½å›¾ç‰‡
print("\nâ±ï¸ æ­¥éª¤ 1: åŠ è½½å›¾ç‰‡...")
step_start = time.time()
import rawpy
import io
with rawpy.imread(TEST_IMAGE) as raw:
    thumb = raw.extract_thumb()
    image = Image.open(io.BytesIO(thumb.data)).convert("RGB")

# ç¼©å°
w, h = image.size
if max(w, h) > 672:
    if w > h:
        new_w, new_h = 672, int(h * 672 / w)
    else:
        new_h, new_w = 672, int(w * 672 / h)
    image = image.resize((new_w, new_h), Image.LANCZOS)
image_load_time = time.time() - step_start
print(f"   å›¾ç‰‡å°ºå¯¸: {image.size}")
print(f"   âœ… ç”¨æ—¶: {image_load_time:.2f}s")

# æ­¥éª¤ 2: åŠ è½½æ¨¡å‹
print("\nâ±ï¸ æ­¥éª¤ 2: åŠ è½½æ¨¡å‹...")
step_start = time.time()
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    "q-future/co-instruct",
    trust_remote_code=True,
    torch_dtype=torch.float16,
    attn_implementation="eager",
    device_map={"": "mps"}
)
model_load_time = time.time() - step_start
print(f"   âœ… ç”¨æ—¶: {model_load_time:.2f}s")

# æ­¥éª¤ 3: ç”Ÿæˆæ ‡é¢˜
print("\nâ±ï¸ æ­¥éª¤ 3: ç”Ÿæˆä¸­æ–‡æ ‡é¢˜...")
step_start = time.time()
prompt = "USER: The image: <|image|> ä¸ºè¿™å¼ ç…§ç‰‡åˆ›ä½œä¸€ä¸ªå¯Œæœ‰è¯—æ„çš„ä¸­æ–‡æ ‡é¢˜ï¼Œ5-10ä¸ªå­—ã€‚ ASSISTANT:"
response = model.chat(prompt, [image], max_new_tokens=30)
inference_time = time.time() - step_start
print(f"   âœ… ç”¨æ—¶: {inference_time:.2f}s")

# ==================== ç»“æœæ±‡æ€» ====================
total_time = time.time() - total_start

print("\n" + "=" * 60)
print("ğŸ“Œ ç”Ÿæˆç»“æœ")
print("=" * 60)
print(f"   æ ‡é¢˜: {response}")

print("\n" + "=" * 60)
print("ğŸ“Š ç”¨æ—¶ç»Ÿè®¡")
print("=" * 60)
print(f"   å›¾ç‰‡åŠ è½½:   {image_load_time:>6.2f}s")
print(f"   æ¨¡å‹åŠ è½½:   {model_load_time:>6.2f}s")
print(f"   AI æ¨ç†:    {inference_time:>6.2f}s")
print("-" * 30)
print(f"   æ€»ç”¨æ—¶:     {total_time:>6.2f}s")
print("=" * 60)
