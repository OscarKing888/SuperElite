# -*- coding: utf-8 -*-
"""
Co-Instruct å•åŠŸèƒ½æµ‹è¯• - è¯¦ç»†ç”»é¢è§£è¯»
"""

import torch
import time
from pathlib import Path
from PIL import Image

# æµ‹è¯•å›¾ç‰‡
TEST_IMAGE = "/Volumes/990PRO4TB/2025/2025-09-20/_Z8L1493.NEF"

print("ğŸ“· Co-Instruct æµ‹è¯• - è¯¦ç»†ç”»é¢è§£è¯»")
print("=" * 60)
print(f"æµ‹è¯•å›¾ç‰‡: {TEST_IMAGE}")

# ==================== è®¡æ—¶å¼€å§‹ ====================
total_start = time.time()

# åŠ è½½å›¾ç‰‡
print("\nâ±ï¸ æ­¥éª¤ 1: åŠ è½½å›¾ç‰‡...")
step_start = time.time()
import rawpy
import io
with rawpy.imread(TEST_IMAGE) as raw:
    thumb = raw.extract_thumb()
    image = Image.open(io.BytesIO(thumb.data)).convert("RGB")

# ç¼©å°
w, h = image.size
if max(w, h) > 672:
    if w > h:
        new_w, new_h = 672, int(h * 672 / w)
    else:
        new_h, new_w = 672, int(w * 672 / h)
    image = image.resize((new_w, new_h), Image.LANCZOS)
print(f"   å›¾ç‰‡å°ºå¯¸: {image.size}")
print(f"   ç”¨æ—¶: {time.time() - step_start:.1f}s")

# åŠ è½½æ¨¡å‹
print("\nâ±ï¸ æ­¥éª¤ 2: åŠ è½½æ¨¡å‹...")
step_start = time.time()
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    "q-future/co-instruct",
    trust_remote_code=True,
    torch_dtype=torch.float16,
    attn_implementation="eager",
    device_map={"": "mps"}
)
model_load_time = time.time() - step_start
print(f"   ç”¨æ—¶: {model_load_time:.1f}s")

# æµ‹è¯•åŠŸèƒ½
print("\n" + "=" * 60)
print("ğŸ”¹ åŠŸèƒ½ 2: è¯¦ç»†ç”»é¢è§£è¯»")
print("=" * 60)

prompt = """USER: The image: <|image|> 
è¯·è¯¦ç»†æè¿°è¿™å¼ ç…§ç‰‡çš„ç”»é¢å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»ä½“æ˜¯ä»€ä¹ˆ
2. ç¯å¢ƒå’ŒèƒŒæ™¯
3. å…‰çº¿æ¡ä»¶
4. è‰²å½©ç‰¹ç‚¹
5. ç”»é¢æ°›å›´å’Œæƒ…æ„Ÿ

ç”¨ä¸­æ–‡å›ç­”ï¼Œå°½å¯èƒ½è¯¦ç»†ã€‚ ASSISTANT:"""

print("\nâ±ï¸ æ­¥éª¤ 3: ç”Ÿæˆæè¿°...")
step_start = time.time()
response = model.chat(prompt, [image], max_new_tokens=500)
inference_time = time.time() - step_start

# è¾“å‡ºç»“æœ
print("\nğŸ“ ç”»é¢è§£è¯»:")
print("-" * 60)
# æ¨¡å‹è¿”å›çš„ä¸­æ–‡ä¼šç›´æ¥æ‰“å°åœ¨è¿™ä¹‹å‰

total_time = time.time() - total_start

print("\n" + "=" * 60)
print("ğŸ“Š ç”¨æ—¶ç»Ÿè®¡")
print("=" * 60)
print(f"   å›¾ç‰‡åŠ è½½: {0.1:.1f}s")
print(f"   æ¨¡å‹åŠ è½½: {model_load_time:.1f}s")
print(f"   AI æ¨ç†:  {inference_time:.1f}s")
print(f"   æ€»ç”¨æ—¶:   {total_time:.1f}s")
print("=" * 60)
